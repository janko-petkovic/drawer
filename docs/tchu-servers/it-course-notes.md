## Booting

**BIOS**: old booting method, MBR, 2 Tb max

**UEFI**: new, entire specialized partition to reference other partitions, secure boot, and other cool stuff



### Boot loaders

**GRUB**: older, called "GRUB legacy", difficult to modifty

- `/boot/grub/menu.lst`, `/boot/grub/grub.conf`

**GRUB2**: probably you are gonna use this

- `/boot/grub/grub.cfg`

- customizations in `/etc/default/grub`

- hold **SHIFT** to get into the hidden boot menu (you don't see it explicitly)

### Boot methods

**Hardware**:

- PXE (preboot execution environment): queries the DHCP server, which provides a boot image in response

- iPXE: HTTP instead of TFTP

- USB, CD, HD

**Software**:

- ISO, I didn't really get what the guy means here

### Boot process (`/boot`, `/lib/modules`)

You want to get the kernel running and loading all the modules. Kind of a chicken/egg problem

BIOS/UEFi > GRUB/2 > `vmlinux/z` (bare kernel file, without modules) > full kernel

`initrd`: enough information for vmlinx to load the modules by mounting some components (mounted alongside of the kernel)

`initramfs`: its the file system used by vmlinux to do what it has to do to load the modules

### Modules

**Loading** modules on boot `/etc/modules`

- put just a name of the module (e.g., `e1000`), it loads automatically

**Blacklisting** `/etc/modprobe.d/blacklist.conf`

- add some corresponding line, e.g.`blacklist modname`

**Runtime** module managing:

- Add modules to running kernel (`.ko`)
  
  - `insmod`: give path, no checks, fails without any explanation
  
  - `modprobe`: give name, manages dependencies, needs a map (`depmob`)

- Remove module `rmmod`

- List active modules `lsmod`



### Troubleshooting

#### Kernel panic

1. Piece of faulty hardware (OC CPU, bad RAM stick, add-on card)

2. Just upgreaded the system
   
   - pick an older kernel to try to troubleshoot (press SHIFT and load another kernel)



#### Network troubleshooting

 `ping`,`ip add`, `ip route`

**DNS** **testing** (`/etc/hosts`)

- `dig [@server] google.com`

- `nslookup host [server]`

- `host host [server]`

**DNS Configuration** files

- `/etc/hosts`: first resort  DNS lookup

- `/etc/nsswitch`: bunch of stuff, also says the query order for the DNS calls

- `/etc/resolv.conf`: tells the name server, automatically generated by network manager

**Network configuration**

- `/etc/network/interfaces` this is how configure on an old system

- `/etc/netplan/some-name.yaml` like the one above but indent properly (run `sudo netplan apply` afterwards)

- network manager tui

- CentOS has a differenct structure, but the basica ideas are the same
  (`/etc/sysconfig/network-scripts`) 

**Network bonding**

- switch support: **balance-rr** (mode 0, for servers talking directly to each other), balance-xor, broadcast, **802.3ad** (mode 4, industry standard, use this)

- generic: active backup, balance-tlb, **balance-alb** (mode 6, use this one for dum switches)

- configuring on ubuntu `/etc/netplan`:  renderer networkd, dhcp4 false, bonds: interfaces: eth0, mode: active-backup > apply and `ip add` or 
  `cat /proc/net/bonding/bond0`



## Storage management

### Memory drives: use GPT

**MBR** (mater boot record): table of contents describing how `/dev/sda` is organized (`sda1`, `sda2`, ...) -> each partition is a device.

**GPT** (Global unique identifier Partition Table): table of contents are copied and scattered with CRC correction across the device. Supports more drive space, and more partitions. BIOS systems can see GPT drives. 

Cool stuff with **protective MBR** - basically the initial section of GPT tells BIOS systems that the drive is not empty, just that they are not interpretable as an MBR. But sometimes you can even give hints about the underlying partitions so that an old system is able to read a GPT drive.



### Linux filesystem

Everything is on a single filesystem. Hard-drive `/dev/sda1` is mounted on `/`. Virtual filesystems: mounted on `/proc/`, `/sys/`. Remote NFS: mounted on `/home/`. USB Drive: mounted on `/media/USB1`.

Everything is mounted on a folder inside the root `/`.



### Creating partitions

Identify block devices in the system: 

- `lsblk`

- `cat /proc/partitions`,

- `ls /dev | grep sd`

`parted` and `gparted`

- the graphical interface is very easy

- CLI: read the help

`fdisk`: the fallback method

- `fdisk /dev/sdb`, press m for help; create a new partition table (g), create new partition (n), default everything basically, view everything's alright (p), write and exit (w)



### Filesystem choice

**ext4**, **xfs**, **btrfs**, **dos**.

XFS is probably the best for our computational usecase 

To create the filesystem on a partition, just use `mkfs.<partition_type>`



### Mounting stuff `lsblk`,`blkid`,`mount`

The interesting thing is mounting by default on boot: `/etc/fstab`: 

UUID/path/label -- mount_point -- fs -- options (defaults) -- dump (0) -- pass (fscheck: 2)

And then run `mount -a`, mounts everything specified in `fstab`



### Scan filesystem

You can only scan a fs once is unmounted. It is therefore good to schedule an automatic scanning at boot, before the device is mounted. 

FLOWCHART: is the fs to be scanned? Is the max number of mounts been reached?

`tune2fs -l /dev/partition`

`tune2fs -c 10 /dev/partition`

Or if you want to just do a one shot scan: `fsck`



### LVM (Logical Volume Manager)

Merge multiple physical volumes into one logical volume and slice it up into whatever you need. Physical volumes (PV) can be anything: hard drives, RAID devices, partitions. 

You combine PVs into one or multiple **volume groups** (VGs) (careful that if there is no redundancy, one PV dies, everything dies).

A slice of the VG  is a **logical volume** (LV).

`pvdisplay` shows whats happening behind the scenes in the machine

How do we build an LVM system:

1. `pvcreate /dev/sdb /dev/sdc ...` (you can use both raw devices and partitions) + `pvdisplay`

2. `vgcreate vg_name /dev/sdb /dev/sdc ...` (to create the actual VG) + `vgdisplay`

3. `lvcreate -L 32G -n lv_name vg_name` (carve the LV from the VG) + `lvdisplay`

The final display outputs where the LV is mounted on, so you can format it using `mkfs` as you would with any mounted drive.

A handy extension utility is `lvextend -L+5G lv_name`, guess what it does.



### RAID Levels (we don't want stuff to go bad)

RAID0: striped array, very quick, one dies everyone dies

RAID1: mirrored array, half the memory, full backup

RAID5: parity disk, safe but you lose one disk (still good though)

Interestingly, you can combine different RAID levels. Whatever, look at the wiki page.

How do we **create a RAID device?**? We can use **nice software** (`fdisk` and `mdadm`)

1. take your disks, create an offset partition on each. **This is important so that you can replace failed disks, resizing the new ones properly.**

2. put the label `fd` (Linux auto RAID) (partition type with L)

3. `mdadm --create --verbose /dev/md0 --level=5 --raid-devices=4 /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1`

4. save this configuration to do it on boot (??): `mdadm --detail --scan > /etc/mdadm/mdadm.conf`

You are configuring the RAID system EVEY TIME YOU ARE BOOTING





## Install, update and configure software

**Tarballs** are a way (installing from source: extract, compile, install) - **they cannot update**

**Package managers (.deb files)**:

- `apt` use this (`rmp` on red hat)

- `aptitude` older, still works, don't use it

- `apt-get` oldest, still works, don't use it 

`dpkg` is used as backend in all these tools, but it does not manage dependencies automatically 

**Configuring APT repos:** `/etc/apt`

- Add the repo address: `sources.list` and `/etc/apt/sources.list.d/`: uncomment or add the respective line

- Add the repo GPG key: `wget -wq0- https://... | apt-key add -`

- Check with `apt-key list`

- Update the repos `apt update`

- `apt install package`

We can add repos also using **PPA** repos: `add-apt-repository ppa:...` and everything is ready by itself.



## Managing users

Create new user (low level procedure):

- Create user with home and shell: `useradd -d /home/suzy -s /bin/bash suzy` 

- Create the password for the user: `passwd suzy` > you'll be prompted to insert pw

- Create the home directory: ...

**Create new user (high level script):** `adduser frank` > you'll be prompted for everything, and everything gets created automatically

**Remove user**:  `userdel -r frank` (removes also the files of frank)

**Modify** some features of some user: `usermod suzy`

 

## User groups

Conceptually each user has a **primary group** (same as username) and a number of **supplementary groups**. The primary group defines to which group a newly created file will belong to. The tools to manage groups follow the same logic from before: `groupadd`, `groupmod` and `groupdel`.

- `groups bob` prints all the groups that `bob` is part of. The first one is his primary group.

- `usermod -a -G public bob` appends `public` as another supplementary group to `bob` (**remember the `-a` otherwise it deletes everything else**)

- `usermod -g public bob` sets `public` as the new primary group for `bob`



**Note:** more updated commands on the ubuntu cheatsheet

**A list of useful nosy commands:**

- `whoami`

- `who` is currently logged into the system (since when, from where)

- `w` (-hat?) basically more compared to `who`

- `pinky` again some different info about the people logged in

- `id user` info about a user

- `last` log of recent logins



### Password files

We don't want that everyone sees everybody else's pwds. Therefore, they invented **shadow files**.

`/etc/passwd` contains all the info about everyone. The pdws are replaced by a placeholder `x`.

`/etc/shadow` contains an encrypted version of each of the user's pwd. When you login, the *system* checks here *with root privileges*.

**Note:** we have a similar system for group passwords with `/etc/gshadow`

**Editing things manually:**

- `sudo vipw` to modify `/etc/passwd`

- `sudo vipw -s` to modify `/etc/shadow` compatibly



### Quotas

Don't let people store a lot of stuff on the server:

- in `/etc/fstab` add the option `usrquota`; you will be able to see it with `mount`

- `sudo quotacheck -au` check the quotas in -all partitions that support quotas for 
  -user owned files. This creates a file `aquota.user` where the device is mounted

- `sudo quotaon -a` activate the quotas

- `sudo edquota bob` activates a prompt where you setup everything (in kb)



### User profiles

**Systemwide configuration**: `/etc/environment`,`/etc/bashrc`,`/etc/profile`. They are applied first, for everyone.

**User specific config:** `/home/user/.bashrc`,`/home/user/.profile`

**Useful commands:**

- redirection: `>`, `|`,`tee`,`xargs`

- text manipulation: `cut`, `paste`, `sort`, `wc`

- `sed`: stream editor, takes input stream and uses kind of vi like command to substitute stuff? Also does other stuff

- `awk` takes input stream and outputs bits `akw '{print $2 " " $1}' file.txt`

- `find <where> -name <what> --additiona-flags` like delete
  
  - `find ~ -samefile my_file.doc` finds all the hard links to the same inode

- `locate oldfile` gives the full path containing `oldfile`. Uses a database cached on the system. To update the cache run `sudo updatedb` (takes a bit but not too much)

### Copying over the network

- `scp any_source any_destination` (keep in mind the addresses `user@machine:path`) 

- `rsync -av any_source any_destination` (`-a` copies everything, also recursively) - the difference with `scp` is that `rsync` uses some *delta transfer algorythm* with optimizations that make the command much faster; `scp` just reads the source file and performs a plain linear copy (https://stackoverflow.com/questions/20244585/how-does-scp-differ-from-rsync). `rsync` also has many other options.



## Manage local services

### `systemd`

Basic manual uses:

- `systemctl status <X>`: current status of the service (running or not)

- `systemctl enable <X>` vs `systemctl disable <X>`: choose if the system starts at boot (or not)

- `systemclt start <X>` vs `systemctl stop <X>`: start or stop the service

- `systemctly restart <X>` restart the service



### Boot targets

`systemd` is also able to manage the **boot targets** (an equivalent of the older **runlevels)** of the systems. The runlevel-target correspondences are:

0. poweroff

1. resque mode

2. nothing

3. multi-user

4. nothing

5. graphical mode

6. reboot

To switch between these boot targets (modes), you can use again `systemctl`:

- `systemctl get-default` output the current system mode

- `systemctly set-default multi-user.target` set the new default mode (activated at boot)

- `systemctl isolate multi-user` switch to the `multi-user` system mode (no GUI in this case)

### Runlevels (old systems)

This is on older systems, and is handled by `SysVinit`; not the usecase today I would guess

0. Halt

1. Single user mode

2. Full, multiuser, GUI if installed

3. nothing

4. nothing

5. nothing

6. Reboot

Red Hat systems have a different table.  



## Understanding network server roles

In the context of a network of servers, there are two families of services:

1. **Centralized** services: run on one server, applied to all (DHCP, DNS, NTP, Config Management)

2. **Individual services**: run on each or most servers (SSH, Config Client, Docker, NTP)

**Note:** really take a look from 4:14:07 in the video (https://www.youtube.com/watch?v=WMy3OzvBWc0&t=4829s), for a great explanation of the conceptual developement of servers, services, virtualization, and containerization (I, for one, understood finally why servers are called servers) 



### Web servers and SSL

Web server: you send a request, and it send's you the webpage back. What about SSL or TLS (encrypted traffic)?

1. The client sends a SSL session request

2. The server answers with a **certificate** to prove its identity

3. The client requests a **verification** from **certificate authority**, which cheks if they have approved the certificate with their own signature

4. the client sends the encryption key to the server

5. the server encrypts with the client's key and sends to the client

6. the communication proceeds back and forth

Another methodology includes **self-signed certificates**: there is no signature from the certificate authority. It's basically based on trust. I don't know why they call it self-signed when it's actually non-signed.



More stuff on server roles, from a more theoretical point of view, is in the video. It doesn't lend itself very well for operative notes.



## Automate and schedule jobs

### System-wide cron jobs

Scheduling fields are separated in 5 sections:

| Minutes                  | Hours     | Day of Month | Months               | Day of Week         |
| ------------------------ | --------- | ------------ | -------------------- | ------------------- |
| */5 (every five minutes) | * (every) | * (every)    | 0-4 (january to may) | 0 (only on Mondays) |

In the example above, we are running some command in every five minutes, every Monday (intersection between the two Days column), on the first five months of the year.

Where to setup the scheduling:

- `/etc/cron.d/` contains jobs scheduled with weird scheme (e.g. a file text with
   `* * * * * * <user> <command>`)

- `/etc/cron.daily`, `/etc/cron.monthly`,... : contain **executables** to be run at the frequency specified in the name



### Scheduling personal events/tasks

We use `crontab -e`. The syntax is the usual one, without the need to specify the user.

For **one-time events** we use the `at` daemon: `at now +1 minute`, into prompt for command insertion (close with Ctrl+D). Remove job with `atrm`.



### Handling foreground and background processes

Some simple commands

- appending `&` to a command, executes it in the background

- `jobs` lists the running jobs

- `fg <job_nr> / bg <job_nr>` runs a job in the foreground/background

-  `Ctrl+Z` suspends the job running in the foregroung

When we log out of the system, all the running processes linked to the user are killed. To avoid this we can use `nohup`.



## Finding local devices and info about them

Some useful commands:

- `dmesg` prints a log regarding all the device-related events that happened since some time

- `ls<something>` (find the something with tab autocompletion): lists different sorts of devices

Also, if you want to find information about running processes, look into `/proc/<id>`.

Due to historical reasons, `/proc/` contains also a lot of other information about kernel elements (like cpu-related info). More information about the running kernel is located in `/sys/`. Basically, look in both.

Information on devices is found in `/dev/`.



### Printing: CUPS

Go to `localhost:631` to interact with the CUPS web interface

Command line:

- `lpr` sends input stream to printer

- `lpq` shows the queue

- `lpr` removes job from the queue



### UDEV

Historically, devices would get their name assigned on recognizement precedence (e.g. `sda`, `sdb` and so on). What `udev` does is creating names based on, for example, UUID (the backend of `udev` is `sysfs`). Another neat thing `udev` does is create **rules:**

- `udevadm info /dev/sr0` shows all the info about `sr0` 

- in `/etc/udev/rules.d/` create some file `example.rules`. It could be like this:

```
KERNEL=="sr0", SUBSYSTEM=="block", SYMLINK="my_dvd"
```

this creates a symling called `my_dvd` pointing at the `sr0` device.


